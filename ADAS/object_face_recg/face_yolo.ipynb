{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 279 face encodings from the dataset.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: List[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n\nInvoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x0000025722956B70>, array([[[199, 197, 199],\n        [199, 197, 199],\n        [199, 197, 199],\n        ...,\n        [ 60,  55,  55],\n        [ 59,  54,  54],\n        [ 58,  53,  53]],\n\n       [[199, 197, 199],\n        [199, 197, 199],\n        [199, 197, 199],\n        ...,\n        [ 59,  54,  54],\n        [ 58,  53,  53],\n        [ 58,  53,  53]],\n\n       [[199, 197, 199],\n        [199, 197, 199],\n        [199, 197, 199],\n        ...,\n        [ 59,  56,  55],\n        [ 60,  57,  56],\n        [ 60,  57,  56]],\n\n       ...,\n\n       [[201, 199, 201],\n        [201, 199, 201],\n        [202, 200, 202],\n        ...,\n        [ 56,  54,  56],\n        [ 56,  54,  56],\n        [ 55,  53,  55]],\n\n       [[204, 202, 204],\n        [203, 201, 203],\n        [203, 201, 203],\n        ...,\n        [ 52,  50,  52],\n        [ 52,  50,  52],\n        [ 50,  48,  50]],\n\n       [[204, 202, 204],\n        [205, 203, 205],\n        [205, 203, 205],\n        ...,\n        [ 48,  46,  48],\n        [ 47,  45,  47],\n        [ 44,  42,  44]]], dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000025722A91AB0>, 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 116\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Perform object detection\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m detected_frame \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[0;32m    119\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYOLOv4 Object Detection\u001b[39m\u001b[38;5;124m'\u001b[39m, detected_frame)\n",
      "Cell \u001b[1;32mIn[1], line 86\u001b[0m, in \u001b[0;36mdetect_objects\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_names[class_ids[i]] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     85\u001b[0m     face_image \u001b[38;5;241m=\u001b[39m frame[y:y\u001b[38;5;241m+\u001b[39mh, x:x\u001b[38;5;241m+\u001b[39mw]\n\u001b[1;32m---> 86\u001b[0m     face_encodings \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_encodings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m face_encodings:  \u001b[38;5;66;03m# Ensure that face_encodings is not empty\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         matches \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mcompare_faces(known_face_encodings, face_encodings[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\face_recognition\\api.py:214\u001b[0m, in \u001b[0;36mface_encodings\u001b[1;34m(face_image, known_face_locations, num_jitters, model)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m raw_landmarks \u001b[38;5;241m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [np\u001b[38;5;241m.\u001b[39marray(\u001b[43mface_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_face_descriptor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_landmark_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_jitters\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m raw_landmark_set \u001b[38;5;129;01min\u001b[39;00m raw_landmarks]\n",
      "\u001b[1;31mTypeError\u001b[0m: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: List[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n\nInvoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x0000025722956B70>, array([[[199, 197, 199],\n        [199, 197, 199],\n        [199, 197, 199],\n        ...,\n        [ 60,  55,  55],\n        [ 59,  54,  54],\n        [ 58,  53,  53]],\n\n       [[199, 197, 199],\n        [199, 197, 199],\n        [199, 197, 199],\n        ...,\n        [ 59,  54,  54],\n        [ 58,  53,  53],\n        [ 58,  53,  53]],\n\n       [[199, 197, 199],\n        [199, 197, 199],\n        [199, 197, 199],\n        ...,\n        [ 59,  56,  55],\n        [ 60,  57,  56],\n        [ 60,  57,  56]],\n\n       ...,\n\n       [[201, 199, 201],\n        [201, 199, 201],\n        [202, 200, 202],\n        ...,\n        [ 56,  54,  56],\n        [ 56,  54,  56],\n        [ 55,  53,  55]],\n\n       [[204, 202, 204],\n        [203, 201, 203],\n        [203, 201, 203],\n        ...,\n        [ 52,  50,  52],\n        [ 52,  50,  52],\n        [ 50,  48,  50]],\n\n       [[204, 202, 204],\n        [205, 203, 205],\n        [205, 203, 205],\n        ...,\n        [ 48,  46,  48],\n        [ 47,  45,  47],\n        [ 44,  42,  44]]], dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x0000025722A91AB0>, 1"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "\n",
    "# Load YOLOv4\n",
    "net = cv2.dnn.readNet(\"yolov4.weights\", \"yolov4.cfg\")\n",
    "\n",
    "# Load the COCO class labels\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    class_names = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Initialize lists for known face encodings and their corresponding names\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "# Define the dataset directory path\n",
    "dataset_dir = \"dataset/\"\n",
    "\n",
    "# Load face encodings and names from the dataset folder\n",
    "for person_name in os.listdir(dataset_dir):\n",
    "    person_dir = os.path.join(dataset_dir, person_name)\n",
    "\n",
    "    if os.path.isdir(person_dir):\n",
    "        for image_name in os.listdir(person_dir):\n",
    "            image_path = os.path.join(person_dir, image_name)\n",
    "\n",
    "            try:\n",
    "                image = face_recognition.load_image_file(image_path)\n",
    "                face_encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "                if face_encodings:\n",
    "                    known_face_encodings.append(face_encodings[0])\n",
    "                    known_face_names.append(person_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "print(f\"Loaded {len(known_face_encodings)} face encodings from the dataset.\")\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "out_layer_indices = net.getUnconnectedOutLayers()\n",
    "if isinstance(out_layer_indices[0], list):\n",
    "    out_layer_indices = [i[0] for i in out_layer_indices]\n",
    "output_layers = [layer_names[i - 1] for i in out_layer_indices]\n",
    "\n",
    "def detect_objects(frame):\n",
    "    height, width, _ = frame.shape\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    \n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    \n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            if isinstance(detection, np.ndarray) and detection.shape[0] > 5:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                \n",
    "                if confidence > 0.5:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "                    \n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "                    \n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "    \n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    \n",
    "    if len(indexes) > 0:\n",
    "        for i in indexes.flatten():\n",
    "            box = boxes[i]\n",
    "            x, y, w, h = box\n",
    "            label = f\"{class_names[class_ids[i]]}: {confidences[i]:.2f}\"\n",
    "            \n",
    "            if class_names[class_ids[i]] == \"person\":\n",
    "                face_image = frame[y:y+h, x:x+w]\n",
    "                face_encodings = face_recognition.face_encodings(face_image)\n",
    "\n",
    "                if face_encodings:  # Ensure that face_encodings is not empty\n",
    "                    matches = face_recognition.compare_faces(known_face_encodings, face_encodings[0])\n",
    "                    face_distances = face_recognition.face_distance(known_face_encodings, face_encodings[0])\n",
    "                    best_match_index = np.argmin(face_distances)\n",
    "\n",
    "                    if matches[best_match_index]:\n",
    "                        name = known_face_names[best_match_index]\n",
    "                    else:\n",
    "                        name = \"unknown person\"\n",
    "                    \n",
    "                    label = f\"{name}: {confidences[i]:.2f}\"\n",
    "            \n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Perform object detection\n",
    "    detected_frame = detect_objects(frame)\n",
    "    \n",
    "    # Display the result\n",
    "    cv2.imshow('YOLOv4 Object Detection', detected_frame)\n",
    "    \n",
    "    # Exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
